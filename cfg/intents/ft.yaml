hyper:
  seed: 42
  epochs: 200
  lr: 0.00005
  train_batch_size: 16
  val_batch_size: 32
  grad_accumulation: 2
model:
  predict_with_generate: True
  generation_max_length: 512
  generation_num_beams: 1
eval:
  eval_strategy: "steps"
  eval_steps: 500
  metric: "overall_micro_f1"
save:
  save_strategy: "steps"
  save_steps: 500
logging:
  logging_step: 100
peft_config:
  inference_mode: False
  r: 8
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules: ["q_proj", "v_proj"]